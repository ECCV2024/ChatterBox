ninja_required_version = 1.3
cxx = c++
nvcc = /usr/local/cuda-11.6/bin/nvcc

cflags = -pthread -B /home/TianYunjie/anaconda3/envs/jack/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/TianYunjie/anaconda3/envs/jack/include -fPIC -O2 -isystem /home/TianYunjie/anaconda3/envs/jack/include -fPIC -DWITH_CUDA -I/Workspace/TianYunjie/PycharmProjects/Jack/model/dino/ops/src -I/home/TianYunjie/anaconda3/envs/jack/lib/python3.11/site-packages/torch/include -I/home/TianYunjie/anaconda3/envs/jack/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/home/TianYunjie/anaconda3/envs/jack/lib/python3.11/site-packages/torch/include/TH -I/home/TianYunjie/anaconda3/envs/jack/lib/python3.11/site-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/home/TianYunjie/anaconda3/envs/jack/include/python3.11 -c
post_cflags = -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
cuda_cflags = -DWITH_CUDA -I/Workspace/TianYunjie/PycharmProjects/Jack/model/dino/ops/src -I/home/TianYunjie/anaconda3/envs/jack/lib/python3.11/site-packages/torch/include -I/home/TianYunjie/anaconda3/envs/jack/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/home/TianYunjie/anaconda3/envs/jack/lib/python3.11/site-packages/torch/include/TH -I/home/TianYunjie/anaconda3/envs/jack/lib/python3.11/site-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/home/TianYunjie/anaconda3/envs/jack/include/python3.11 -c
cuda_post_cflags = -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17
cuda_dlink_post_cflags = 
ldflags = 

rule compile
  command = $cxx -MMD -MF $out.d $cflags -c $in -o $out $post_cflags
  depfile = $out.d
  deps = gcc

rule cuda_compile
  depfile = $out.d
  deps = gcc
  command = $nvcc  $cuda_cflags -c $in -o $out $cuda_post_cflags





build /Workspace/TianYunjie/PycharmProjects/Jack/model/dino/ops/build/temp.linux-x86_64-cpython-311/Workspace/TianYunjie/PycharmProjects/Jack/model/dino/ops/src/cpu/ms_deform_attn_cpu.o: compile /Workspace/TianYunjie/PycharmProjects/Jack/model/dino/ops/src/cpu/ms_deform_attn_cpu.cpp
build /Workspace/TianYunjie/PycharmProjects/Jack/model/dino/ops/build/temp.linux-x86_64-cpython-311/Workspace/TianYunjie/PycharmProjects/Jack/model/dino/ops/src/cuda/ms_deform_attn_cuda.o: cuda_compile /Workspace/TianYunjie/PycharmProjects/Jack/model/dino/ops/src/cuda/ms_deform_attn_cuda.cu
build /Workspace/TianYunjie/PycharmProjects/Jack/model/dino/ops/build/temp.linux-x86_64-cpython-311/Workspace/TianYunjie/PycharmProjects/Jack/model/dino/ops/src/vision.o: compile /Workspace/TianYunjie/PycharmProjects/Jack/model/dino/ops/src/vision.cpp







